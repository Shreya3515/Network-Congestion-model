{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFx20GGXOx3L"
      },
      "source": [
        "## AS ORIGINAL DATA IS NOT BEEN PROVIDED WITH THE SUBBMISSION, PLEASE COPY \n",
        "## THE ORIGINAL DATASET INTO THE SAME FOLDER AS THIS CODE BEFORE \n",
        "## EXECUTING.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Importing Dataset\n",
        "df = pd.read_csv(\"train_upd.csv\")\n",
        "\n",
        "# Merging Date-Time\n",
        "df['date']=df['par_day'].map(str)+\"/\"+df['par_month'].map(str)+\"/\"+df['par_year'].map(str)\n",
        "df['par_min'] = df['par_min'] - 5\n",
        "df['time'] = df['par_hour'].map(str) + \":\" + df['par_min'].map(str)\n",
        "df['day-time'] = df['date'].map(str) + \" \" + df['time'].map(str)\n",
        "\n",
        "# Merging all the data features and taking LOG of all the features\n",
        "data_features = ['web_browsing_total_bytes','video_total_bytes', 'social_ntwrking_bytes',\n",
        "       'cloud_computing_total_bytes', 'web_security_total_bytes',\n",
        "       'gaming_total_bytes', 'health_total_bytes', 'communication_total_bytes',\n",
        "       'file_sharing_total_bytes', 'remote_access_total_bytes',\n",
        "       'photo_sharing_total_bytes', 'software_dwnld_total_bytes',\n",
        "       'marketplace_total_bytes', 'storage_services_total_bytes',\n",
        "       'audio_total_bytes', 'location_services_total_bytes',\n",
        "       'presence_total_bytes', 'advertisement_total_bytes',\n",
        "       'system_total_bytes', 'voip_total_bytes', 'speedtest_total_bytes',\n",
        "       'email_total_bytes', 'weather_total_bytes', 'media_total_bytes',\n",
        "       'mms_total_bytes', 'others_total_bytes', \"subscriber_count\"]\n",
        "df['total_data'] = df[data_features].sum(axis = 1)\n",
        "df['log(total_data)'] = np.log(df['total_data'] + 1)\n",
        "\n",
        "for col in data_features:\n",
        "    df[\"log( \" + col + \" )\"] = np.log(df[col]+1)\n",
        "\n",
        "# Creating MAJOR, MINOR and other features        \n",
        "major1 = ['web_browsing_total_bytes','video_total_bytes', 'social_ntwrking_bytes']\n",
        "major2 = ['cloud_computing_total_bytes','communication_total_bytes','presence_total_bytes']\n",
        "\n",
        "minor = ['web_security_total_bytes',\n",
        "       'gaming_total_bytes', 'health_total_bytes', \n",
        "       'file_sharing_total_bytes', 'remote_access_total_bytes',\n",
        "       'photo_sharing_total_bytes', 'software_dwnld_total_bytes',\n",
        "       'marketplace_total_bytes', 'storage_services_total_bytes',\n",
        "       'audio_total_bytes', 'location_services_total_bytes',\n",
        "        'advertisement_total_bytes',\n",
        "       'system_total_bytes', 'voip_total_bytes', 'speedtest_total_bytes',\n",
        "       'email_total_bytes', 'weather_total_bytes', 'media_total_bytes',\n",
        "       'mms_total_bytes', 'others_total_bytes']\n",
        "\n",
        "df['MAJOR(1)'] = df[major1].sum(axis = 1)\n",
        "df['MAJOR(2)'] = df[major2].sum(axis = 1)\n",
        "df['MINOR'] = df[minor].sum(axis = 1)\n",
        "\n",
        "df['MAJOR(1)/MINOR'] = df['MAJOR(1)']/df['MINOR']\n",
        "df['MAJOR(2)/MINOR'] = df['MAJOR(2)']/df['MINOR']\n",
        "df[\"log(minor)\"] = np.log(df['MINOR'])\n",
        "\n",
        "# Calculating total_data/subs_count\n",
        "df['total_data/subs_count'] = df[\"total_data\"]/df[\"subscriber_count\"]\n",
        "df['LOG(total_data/subs_count)'] = np.log(df['total_data/subs_count'])\n",
        "\n",
        "# Creating weekend feature\n",
        "df[\"mod_day\"] = df[\"par_day\"] % 7\n",
        "df.loc[df.mod_day <= 2 , \"weekend\"] = 1\n",
        "df.loc[df.mod_day > 2 , \"weekend\"] = 0\n",
        "\n",
        "# One-hot encoding ran_vendor\n",
        "df = pd.concat([df, pd.get_dummies(df[\"ran_vendor\"])], axis = 1)\n",
        "\n",
        "# One-hot encode different interval of day\n",
        "df.loc[df.par_hour <= 7 , \"day_part\"] = \"night\"\n",
        "df.loc[(df.par_hour <= 17) & (7 < df.par_hour), \"day_part\"] = \"work\"\n",
        "df.loc[(df.par_hour <= 23) & (17 < df.par_hour), \"day_part\"] = \"evening\"\n",
        "\n",
        "df = pd.concat([df, pd.get_dummies(df[\"day_part\"])], axis = 1)\n",
        "\n",
        "# Droping useless columns\n",
        "df = df.drop([\"mod_day\", \"day_part\"], axis = 1)\n",
        "\n",
        "df.to_csv(\"modified_data.csv\", index = False)\n",
        "\n",
        "#------------------------  Preprocessing Test Data  -----------------------------------#\n",
        "# Importing Dataset\n",
        "df = pd.read_csv(\"test_upd.csv\")\n",
        "\n",
        "# Merging Date-Time\n",
        "df['date']=df['par_day'].map(str)+\"/\"+df['par_month'].map(str)+\"/\"+df['par_year'].map(str)\n",
        "df['par_min'] = df['par_min'] - 5\n",
        "df['time'] = df['par_hour'].map(str) + \":\" + df['par_min'].map(str)\n",
        "df['day-time'] = df['date'].map(str) + \" \" + df['time'].map(str)\n",
        "\n",
        "# Merging all the data features and taking LOG of all the features\n",
        "data_features = ['web_browsing_total_bytes','video_total_bytes', 'social_ntwrking_bytes',\n",
        "       'cloud_computing_total_bytes', 'web_security_total_bytes',\n",
        "       'gaming_total_bytes', 'health_total_bytes', 'communication_total_bytes',\n",
        "       'file_sharing_total_bytes', 'remote_access_total_bytes',\n",
        "       'photo_sharing_total_bytes', 'software_dwnld_total_bytes',\n",
        "       'marketplace_total_bytes', 'storage_services_total_bytes',\n",
        "       'audio_total_bytes', 'location_services_total_bytes',\n",
        "       'presence_total_bytes', 'advertisement_total_bytes',\n",
        "       'system_total_bytes', 'voip_total_bytes', 'speedtest_total_bytes',\n",
        "       'email_total_bytes', 'weather_total_bytes', 'media_total_bytes',\n",
        "       'mms_total_bytes', 'others_total_bytes', \"subscriber_count\"]\n",
        "df['total_data'] = df[data_features].sum(axis = 1)\n",
        "df['log(total_data)'] = np.log(df['total_data'] + 1)\n",
        "\n",
        "for col in data_features:\n",
        "    df[\"log( \" + col + \" )\"] = np.log(df[col]+1)\n",
        "\n",
        "# Creating MAJOR, MINOR and other features        \n",
        "major1 = ['web_browsing_total_bytes','video_total_bytes', 'social_ntwrking_bytes']\n",
        "major2 = ['cloud_computing_total_bytes','communication_total_bytes','presence_total_bytes']\n",
        "\n",
        "minor = ['web_security_total_bytes',\n",
        "       'gaming_total_bytes', 'health_total_bytes', \n",
        "       'file_sharing_total_bytes', 'remote_access_total_bytes',\n",
        "       'photo_sharing_total_bytes', 'software_dwnld_total_bytes',\n",
        "       'marketplace_total_bytes', 'storage_services_total_bytes',\n",
        "       'audio_total_bytes', 'location_services_total_bytes',\n",
        "        'advertisement_total_bytes',\n",
        "       'system_total_bytes', 'voip_total_bytes', 'speedtest_total_bytes',\n",
        "       'email_total_bytes', 'weather_total_bytes', 'media_total_bytes',\n",
        "       'mms_total_bytes', 'others_total_bytes']\n",
        "\n",
        "df['MAJOR(1)'] = df[major1].sum(axis = 1)\n",
        "df['MAJOR(2)'] = df[major2].sum(axis = 1)\n",
        "df['MINOR'] = df[minor].sum(axis = 1)\n",
        "\n",
        "df['MAJOR(1)/MINOR'] = df['MAJOR(1)']/df['MINOR']\n",
        "df['MAJOR(2)/MINOR'] = df['MAJOR(2)']/df['MINOR']\n",
        "df[\"log(minor)\"] = np.log(df['MINOR'])\n",
        "\n",
        "# Calculating total_data/subs_count\n",
        "df['total_data/subs_count'] = df[\"total_data\"]/df[\"subscriber_count\"]\n",
        "df['LOG(total_data/subs_count)'] = np.log(df['total_data/subs_count'])\n",
        "\n",
        "# Creating weekend feature\n",
        "df[\"mod_day\"] = df[\"par_day\"] % 7\n",
        "df.loc[df.mod_day <= 2 , \"weekend\"] = 1\n",
        "df.loc[df.mod_day > 2 , \"weekend\"] = 0\n",
        "\n",
        "# One-hot encoding ran_vendor\n",
        "df = pd.concat([df, pd.get_dummies(df[\"ran_vendor\"])], axis = 1)\n",
        "\n",
        "# One-hot encode different interval of day\n",
        "df.loc[df.par_hour <= 7 , \"day_part\"] = \"night\"\n",
        "df.loc[(df.par_hour <= 17) & (7 < df.par_hour), \"day_part\"] = \"work\"\n",
        "df.loc[(df.par_hour <= 23) & (17 < df.par_hour), \"day_part\"] = \"evening\"\n",
        "\n",
        "df = pd.concat([df, pd.get_dummies(df[\"day_part\"])], axis = 1)\n",
        "\n",
        "# Droping useless columns\n",
        "df = df.drop([\"mod_day\", \"day_part\"], axis = 1)\n",
        "\n",
        "# dumping csv file\n",
        "df.to_csv(\"modified_data_test.csv\", index = False)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}